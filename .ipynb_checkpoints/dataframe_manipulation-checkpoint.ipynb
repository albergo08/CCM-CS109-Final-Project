{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from itertools import product\n",
    "import json \n",
    "import csv\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#dataframe for the finding API, will be merged with the shopping GetSingleItem\n",
    "df_finding=pd.read_json(\"./data/completedItems.json\")\n",
    "\n",
    "\n",
    "df_getsingleitem = pd.read_json(\"./data/getSingleItem.json\")\n",
    "df_getsingleitem=df_getsingleitem.rename(columns = {'ItemID':'itemId'})\n",
    "#df_getsingleitem.head()\n",
    "\n",
    "\n",
    "df_UserProfile=pd.read_json(\"./data/getUserProfile.json\")\n",
    "#df_UserProfile.head()\n",
    "\n",
    "#df_UserProfile.head(1880)\n",
    "\n",
    "\n",
    "\n",
    "#df_getsingleitem.head(100)\n",
    "\n",
    "#df = pd.merge(df_finding, df_getsingleitem, on='IDHash', how='outer')\n",
    "#df.head(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to take each cell in a column when the cell is actually a dictionary. \n",
    "Each value in the dictionary is added to a new column of the dataframe based on its key\n",
    "\"\"\" \n",
    "\n",
    "#my code here \n",
    "def column_dict_expander(df,column):\n",
    "    for key in df[column][0].keys():\n",
    "        templist = []\n",
    "        print key\n",
    "        counter = 0\n",
    "        for i in df.index:\n",
    "            counter +=1\n",
    "            dictionary = df[column][i]\n",
    "            if isinstance(dictionary,dict):\n",
    "                if key in dictionary.keys():\n",
    "                    val = dictionary[key]\n",
    "            else:\n",
    "                val = 'NaN'\n",
    "            templist.append(val)\n",
    "        df[key] = templist\n",
    "    df = df.drop(column, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedbackRatingStar\n",
      "UserID\n",
      "FeedbackScore\n",
      "PositiveFeedbackPercent\n",
      "Status\n",
      "PositiveFeedbackPercent\n",
      "SellerBusinessType\n",
      "NewUser\n",
      "UserID\n",
      "FeedbackRatingStar\n",
      "FeedbackPrivate\n",
      "FeedbackScore\n",
      "FeedbackDetailsURL\n",
      "SellerItemsURL\n",
      "RegistrationSite\n",
      "RegistrationDate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor key in df_UserProfile['User'][0].keys():\\n    templist = []\\n    print key\\n    for i in df_UserProfile.index:\\n        if df_UserProfile['Ack'][i] == 'Success':\\n            val = df_UserProfile['User'][i][key]\\n        else:\\n            val = 'NaN'\\n        templist.append(val)\\n    df_UserProfile[key] = templist\\n    \\n    \\n    \\nfor key in df_getsingleitem['Seller'][0].keys():\\n    templist = []\\n    print key\\n    counter = 0\\n    for i in df_getsingleitem.index:\\n        counter +=1\\n        if key in df_getsingleitem['Seller'][i].keys():\\n            if df_getsingleitem['Seller'][i][key] != 'NaN':\\n                val = df_getsingleitem['Seller'][i][key]\\n        else:\\n            val = 'NaN'\\n        templist.append(val)\\n    df_getsingleitem[key] = templist\\n\""
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is to expand some of the columns that have dicitonaries of information.\n",
    "# I go into each dictionary and make a new column based on each key in the dictionary\n",
    "# with the function I defined above \n",
    "\n",
    "\n",
    "df_getsingleitem = column_dict_expander(df_getsingleitem,'Seller')\n",
    "df_UserProfile = column_dict_expander(df_UserProfile,'User')\n",
    "\n",
    "\"\"\"\n",
    "for key in df_UserProfile['User'][0].keys():\n",
    "    templist = []\n",
    "    print key\n",
    "    for i in df_UserProfile.index:\n",
    "        if df_UserProfile['Ack'][i] == 'Success':\n",
    "            val = df_UserProfile['User'][i][key]\n",
    "        else:\n",
    "            val = 'NaN'\n",
    "        templist.append(val)\n",
    "    df_UserProfile[key] = templist\n",
    "    \n",
    "    \n",
    "    \n",
    "for key in df_getsingleitem['Seller'][0].keys():\n",
    "    templist = []\n",
    "    print key\n",
    "    counter = 0\n",
    "    for i in df_getsingleitem.index:\n",
    "        counter +=1\n",
    "        if key in df_getsingleitem['Seller'][i].keys():\n",
    "            if df_getsingleitem['Seller'][i][key] != 'NaN':\n",
    "                val = df_getsingleitem['Seller'][i][key]\n",
    "        else:\n",
    "            val = 'NaN'\n",
    "        templist.append(val)\n",
    "    df_getsingleitem[key] = templist\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-412-678e493dd3ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#turns item ID entries from 1-element lists to just the contents inside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_finding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_finding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#convert type of item ID entries to ints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_finding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_finding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2060\u001b[0;31m         \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2061\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:58435)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-412-678e493dd3ac>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#turns item ID entries from 1-element lists to just the contents inside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_finding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_finding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#convert type of item ID entries to ints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_finding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_finding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "##FOR MERGING THE TWO DATAFRAMES ABOUT ITEM\n",
    "\n",
    "\n",
    "#turns item ID entries from 1-element lists to just the contents inside\n",
    "df_finding['itemId'] = df_finding.itemId.apply(lambda r: r[0])\n",
    "#convert type of item ID entries to ints\n",
    "df_finding['itemId'] = df_finding.itemId.apply(lambda r: int(r))\n",
    "\n",
    "df_items = pd.merge(df_finding, df_getsingleitem, on='itemId', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MERGING THE FIRST TWO WITH THE ONE ABOUT THE SELLER\n",
    "\n",
    "df_total = pd.merge(df_items, df_UserProfile, on='UserID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9629\n"
     ]
    }
   ],
   "source": [
    "df_total.head()\n",
    "print len(df_total.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEXT, we will expad some more columns and delete others that we just don't need to do our analysis. This could even come at the end once we figure out which aren't useful, but must remember to put it here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def de_list(r):\n",
    "    if type(r) == list and len(r) > 0:\n",
    "        return r[0]\n",
    "    elif type(r) == list and len(r) == 0:\n",
    "        return None\n",
    "    elif type(r) != list:\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditionId\n",
      "conditionDisplayName\n",
      "listingType\n",
      "gift\n",
      "bestOfferEnabled\n",
      "startTime\n",
      "buyItNowAvailable\n",
      "endTime\n",
      "categoryId\n",
      "categoryName\n",
      "expeditedShipping\n",
      "shippingType\n",
      "handlingTime\n",
      "oneDayShippingAvailable\n",
      "shipToLocations\n",
      "ReturnsAccepted\n"
     ]
    }
   ],
   "source": [
    "for col in df_total.columns:\n",
    "    df_total[col] = df_total[col].apply(de_list)\n",
    "\n",
    "df_total = column_dict_expander(df_total,'condition')\n",
    "df_total = column_dict_expander(df_total,'listingInfo')\n",
    "df_total = column_dict_expander(df_total,'primaryCategory')\n",
    "#df_total = column_dict_expander(df_total,'productId')\n",
    "df_total = column_dict_expander(df_total,'shippingInfo')\n",
    "df_total = column_dict_expander(df_total,'ReturnPolicy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#getting just one value from a column and keeping that column name rather than expanding a whole dictionary\n",
    "#like right above\n",
    "counter = 0\n",
    "for i in df_total.index:\n",
    "    #counter += 1\n",
    "    #print counter\n",
    "    \n",
    "    if pd.isnull(df_total['CurrentPrice'].values[i]) == False:\n",
    "        df_total['CurrentPrice'].values[i] = df_total['CurrentPrice'].values[i][u'Value']\n",
    "    \n",
    "    if pd.isnull(df_total['BuyItNowPrice'].values[i]) == False:\n",
    "        df_total['BuyItNowPrice'].values[i] = df_total['BuyItNowPrice'].values[i][u'Value']\n",
    "    if pd.isnull(df_total['MinimumToBid'].values[i]) == False:\n",
    "        df_total['MinimumToBid'].values[i] = df_total['MinimumToBid'].values[i][u'Value']\n",
    "    if pd.isnull(df_total['ProductID'].values[i]) == False:\n",
    "        df_total['ProductID'].values[i] = df_total['ProductID'].values[i][u'Value']\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Now we will do some Feature engineering\n",
    "\n",
    "This is to figure out which variables actually make a distinction on profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9629, 107)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We delete the columns that are irrelevant to our analysis. For example, DiscountPriceInfo tells us no information about our data, because none of our auctions have discounted prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df_total['Charity'], df_total['Country'], df_total['ConvertedCurrentPrice'], df_total['DiscountPriceInfo']\n",
    "del df_total['ListingStatus'], df_total['PaymentAllowedSite'], df_total['ReserveMet'], df_total['SKU']\n",
    "del df_total['Site'], df_total['Storefront']\n",
    "del df_total['Subtitle'], df_total['TimeLeft'], df_total['ViewItemURLForNaturalSearch'], df_total['ConvertedBuyItNowPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then remove unnecessary information from each of the columns. For example, on CurrentPrice, we only want the value in the dictionary and not the whole dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-267-2a2db1e8cf48>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-267-2a2db1e8cf48>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    df['paymentMethod'] = df['paymentMethod'].map({'[PayPal]': 0, ''})\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#df['CurrentPrice'].values[3][u'Value']\n",
    "\n",
    "df['ListingType'] = df['ListingType'].map({'Chinese': 0, 'FixedPriceItem': 1})\n",
    "df['paymentMethod'] = df['paymentMethod'].map({'[PayPal]': 0, ''})\n",
    "df['country'] = df['country'].map({'US': 0 else1})\n",
    "\n",
    "#because each auction we are dealing with is completed, we say\n",
    "df=df.rename(columns = {'CurrentPrice':'FinalPrice'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftouse = df_total.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can now make some separator variables to make listings unique**\n",
    "\n",
    "Certain parameters that are zero are can be significant indicators of specific characteristics of an auction. For example, if the HitCount is zero, that means nobody really bothered to interact with the auction at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ZERO_IMPORTANT_VARIABLES = ['BidCount', 'HitCount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mark binary or indicator variables, we see which of the dataframe fall into this category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-319-6ab31997446a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdftouse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/nanops.pyc\u001b[0m in \u001b[0;36munique1d\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyObjectHashTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ensure_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.unique (pandas/hashtable.c:13637)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "for v in df.columns:\n",
    "    l=dftouse[v].unique()\n",
    "    if len(l) <= 10:\n",
    "        print v, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
